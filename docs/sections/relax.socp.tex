\documentclass[../main]{subfiles}
\title{Relaxations for QCQP}
\author{Chuwen Zhang}
\date{\today}
\begin{document}
\maketitle
{
  \setcounter{tocdepth}{3}
  \tableofcontents
}

\section{Relaxations for General QCQP}


\subsection{SOCP Relaxation}

We now consider another way of relaxing the original QCQP problem. Consider symmetric indefinite matrix \(Q \in \mathcal{S}^n\) and its spectral decomposition.

\begin{equation}
  \begin{aligned}
     & Q = V\Lambda V ^T =\sum_j^n \lambda_j v_j  v_j^T \\
     & \Lambda = \mathrm{diag}(\lambda)
  \end{aligned}
\end{equation}

Without loss of generality, we assume first \(r\) eigenvalues are positive, \(\lambda_1, ..., \lambda_r \ge 0, r\le n \). The quadratic form \(x^TQx\) can also be partitioned into positive and negative parts:

\begin{equation}\label{eq:qpform}
  \begin{aligned}
    x^TQx = \sum_{j=1}^r \lambda_j x^T v_j v_j^T x + \sum_{j=r+1}^n \lambda_j x^T v_j v_j^T x
  \end{aligned}
\end{equation}

By letting \(y_j \ge z_j^2, z_j = v_j^T x, j = 1, \cdots, n\), then \eqref{eq:qpform} can be expressed by introducing \(n\) (2-\(d\)) quadratic cones, literally,

\begin{equation}
  \begin{aligned}
    x^TQx \le \sum_j y_j \cdot \lambda_j,\; (y_j, v^T_j x) \in \mathcal{Q}^2
  \end{aligned}
\end{equation}

This substitution uses a set of small quadratic cones instead of one semidefinite matrix of size \(n^2\). With some abuse of notation, suppose \(\lambda_i, V_i, i = 0, \cdots, m\) are eigenvalues and vectors for \(Q\) and \(A_i, i = 1,
\cdots, m\), respectively. Following the same routine for each constraint, we describe the Many-Small-Cone (MSC) relaxation to QCQP, namely,

\begin{equation}\label{eq.rel.msc}
  \begin{aligned}
    \model{MSC} \quad \mathrm{Maximize: }\quad & y_0 ^T\lambda_0 + q^Tx                              \\
    \mathrm{s.t.} \quad                        & V_i z_i = x                        & i=0,...,m      \\
                                               & y_i ^T\lambda_i  + a_i^Tx  \le b_i & i=1,...,m      \\
                                               & y_i \ge z_i \circ z_i              & i=0,...,m      \\
                                               & y_i^Te \le x^Te                    & i=0, \cdots, m
  \end{aligned}
\end{equation}
The last set of constraints are placed to resolve unboundedness for the fact that the similarity transformation by any orthogonal basis \(V_i, \forall i\) preserves the value of \(\trace\) operator, namely:
\begin{equation}
  y_i^Te = \trace( V_i^Txx^T V_i) = \trace (xx^T) \le x^Te
\end{equation}

This method is closely related to D.C. and Convex SOCP relaxations to QCQP, see \cite{zheng_convex_2011}, \cite{zheng_nonconvex_2011}, \cite{jiang_simultaneous_2016}, \cite{ye_new_2003}. Recently, \cite{luo_new_2019} mention a similar formulation, by defining \(C_i = V_i\diag(\sqrt{|\lambda_i|}|)\). Then the bounds can be put on weighted sum of \(y\)
\begin{equation} \label{eq.rel.luo} y^T\frac{1}{|\lambda|}  \le x^Te, i=0, \cdots, m
\end{equation}


In \cite{luo_new_2019}, box constraints for \(z_i\) can be calculated by its definition. For the case where \(x\in [0, 1]\), we show bounds are redundant and the two formulations are equivalent.

\begin{proposition}
  The relaxations \eqref{eq.rel.msc}, \eqref{eq.rel.luo} are equivalent.
\end{proposition}
It can be shown the solution for any one of the relaxations can be derived from another.  Suppose $(x_0, z_0, y_0)$ is a feasible solution to \eqref{eq.rel.msc}, then $(x_0, \sqrt{\diag(|\lambda|)} z_0, \diag(|\lambda|) \cdot y_0)$ is feasible to \eqref{eq.rel.luo}. Conversely, if $(x_0, z_0, y_0)$ is feasible to \eqref{eq.rel.luo}, then we can construct $(x_0, \frac{1}{\sqrt{\diag(|\lambda|)}} z_0, \frac{1}{\diag(|\lambda|)}\cdot y_0)$ that is also feasible to \eqref{eq.rel.msc}.

One can also scale the quadratic constraints by inspecting the most negative eigenvalue, one uses,
\begin{align*}
   & x^T(Q_i+t_i I_n) x+q_i^T x \leqslant b_i+ t_i \cdot s,i= 1,\dots, m \\
   & \|x\|^2 \le s
\end{align*}

\end{document}