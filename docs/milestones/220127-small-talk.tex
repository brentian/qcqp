\documentclass[aspectratio=1610, 10pt]{beamer}
\usepackage[english]{babel}
\usepackage{amsmath, amsthm, subfiles, bm, hyperref, graphicx}
\usepackage{mathrsfs}
\usepackage{caption, longtable, booktabs}
\usepackage{cancel}

% my cmd
%%%%%%%%%%%%%%%%
% start my commands
%%%%%%%%%%%%%%%%
\newcommand{\lm}{\lambda_\textrm{max}}
\newcommand{\trace}{\mathbf{trace}}
\newcommand{\diag}{\mathbf{diag}}
\newcommand{\model}[1]{(\textbf{#1})}
\newcommand{\mx}{\mathbf{\max}\;}
\newcommand{\mn}{\mathbf{\min}\;}
\newcommand{\st}{\mathrm{s.t.\;}}
\newcommand{\ex}{\mathbf E}
\newcommand{\dx}{\;\bm dx}
\newcommand{\pr}{\mathbf P}
\newcommand{\id}{\mathbf I}
\newcommand{\bp}{\mathbb P}
\newcommand{\be}{\mathbb E}
\newcommand{\bi}{\mathbb I}
\newcommand{\bxi}{{\bm \xi}}
\newcommand{\va}{\mathbf{Var}}
\newcommand{\dif}{\mathbf{d}}
\newcommand{\minp}[2]{\min\{#1, #2\}}
\newcommand{\intp}{\mathbf{int}}
\newcommand{\apex}{\mathbf{apex}}
\newcommand{\conv}{\mathbf{conv}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\usefonttheme[onlymath]{serif}

%%%%%%%%%%%%%%%%
% finish my commands
%%%%%%%%%%%%%%%%

% theorem environments
\setbeamertemplate{footline}[frame number]


\makeatletter
\patchcmd{\beamer@sectionintoc}
{\ifnum\beamer@tempcount>0}
{\ifnum\beamer@tempcount>-1}
{}
{}
\beamer@tocsectionnumber=0
\makeatother

% set the toc to be using the number
\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{subsection in toc}[subsections numbered]

\hypersetup{pdfstartview={Fit}}

\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table of Contents}
        \tableofcontents[        currentsection,         currentsubsection,         subsectionstyle=show/shaded/hide,]
    \end{frame}
}


\defbeamertemplate{section page}{mine}[1][]{%
    \begin{centering}
        \vskip1em\par
        \begin{beamercolorbox}[sep=12pt, center]{part title}
            \usebeamerfont{section title}\insertsection\par
        \end{beamercolorbox}
    \end{centering}
}

\defbeamertemplate{subsection page}{mine}[1][]
{
    \begingroup
    \begin{beamercolorbox}[sep=8pt, center]{subsection title}
        \usebeamerfont{subsection title}\insertsubsection\par
    \end{beamercolorbox}
    \endgroup
}


\setbeamertemplate{section page}[mine]
\setbeamertemplate{subsection page}[mine]

\begin{document}


\title{QCQP: Project Report}

\author{
  Chuwen Zhang, Yinyu Ye
}


\maketitle
\begin{frame}{The QCQP}
  We consider the homogeneous QCQP,
  \begin{equation}
    \begin{aligned}
      \model{HQCQP} \quad \mx \quad & x^T Qx                                  \\
      \text{s.t. } \quad            & x^T A_i x \hspace{0.27em} (\le, =, \ge)
      \hspace{0.27em} b_i, \forall i = 1, \ldots, m                           \\
    \end{aligned}
  \end{equation}
  and inhomogeneous QCQP,
  \begin{equation}
    \label{eq:inhoqcqp}
    \begin{aligned}
      \model{QCQP} \quad \mx \quad & x^T Qx + q^T x                                    \\
      \textrm{s.t.} \quad          & x^T A_i x + a_i^T x \hspace{0.27em} (\le, =, \ge)
      \hspace{0.27em} b_i
    \end{aligned}
  \end{equation}
\end{frame}
\begin{frame}{QCQP Applications}
  \begin{itemize}
    \item Hub-Location, Quadratic Assignment,
    \item Sensor Network Localization, Ball Packing, Kissing Number,...
    \item Gurobi is using LP + branch and bound to solve QCQP
    \item Is it possible to globally solve QCQP via SDP and SOCP based methods?
  \end{itemize}
\end{frame}
\begin{frame}[allowframebreaks]{Lifting for QCQP}
  The ``Lifting'' trick is to introduce \(Y \succeq xx^T\)
  \begin{equation}
    \label{eq:shor_basic}
    \begin{aligned}
      \model{Shor} \quad \mx \quad & Q \bullet Y + q^T x                                              \\
      \textrm{s.t.} \quad          & Y - xx^T \succeq 0 \text{ or } \left[
      \begin{array}{cc}
          1 & x^T \\
          x & Y
        \end{array} \right] \succeq 0                                                     \\
                                   & A_i \bullet Y + a_i^T x \hspace{0.27em} \le \hspace{0.27em} b_i,
    \end{aligned}
  \end{equation}
  by adding an auxillary variable, we have the homogenized problem
  $t \in \{- 1, 1\}$,
  \begin{equation}
    \label{eq:shor_homo}
    \begin{aligned}
      \model{HShor} \quad \mx \quad & \left[ \begin{array}{cc}
          Q       & q / 2 \\
          q^T / 2 & 0
        \end{array} \right] \tilde{X}                                              \\
      \textrm{s.t.} \quad           & \tilde{X} = \left[ \begin{array}{c}
          x \\
          t
        \end{array} \right] \left[ \begin{array}{c}
          x \\
          t
        \end{array} \right]^T
    \end{aligned}
  \end{equation}
  \framebreak
  \begin{itemize}
    \item LP or SDP can be used to solve the lifted relaxation. One can use branch and bound techniques. \cite{linderoth_simplicial_2005}, and many others...
    \item Gurobi uses LP and cutting planes to solve node relaxations
    \item SDP based algorithm provides good relaxation bound, in some special cases, SDP is exact. \cite{ye_new_2003}, \cite{sturm_cones_2003}, \cite{burer_exact_2019}, \cite{wang_new_2021}
    \item To use SDP as a node relaxation is expensive.
    \item Motivation: can we use \emph{weaker but quicker} SOCP for relaxation?
  \end{itemize}
\end{frame}

% \begin{frame}[allowframebreaks]{Lift-and-Project: LP based Method}
%   A typical BB framework using lifted matrix \(X\)...\cite{audet_branch_2000}, \cite{linderoth_simplicial_2005}

%   \begin{enumerate}
%     \item Solve the lifted formulation \textcolor{red}{without} \(X\succeq 0\)
%     \item Spatial branching such as \(x \le l \vee x \ge u\)
%     \item Cutting planes
%           \SubItem{1} minimize \(\|X^{n} - xx^T\|\) (rank-one approximation)
%           \SubItem{2} ensure \(X \succeq 0\) SDP cuts, for example, ensure \(2\times 2, 3\times 3\) matrix minors are PSD.
%           \SubItem{3} and so on..
%   \end{enumerate}
%   Another set of important cutting planes for Lift-and-Project is the McCormick envelop (or RLT), for example, if \(x \in [l, u]\)
%   \begin{equation}
%     (x-l)(x-u)^T \le 0
%   \end{equation}

% \end{frame}


\begin{frame}[allowframebreaks]{Rank-\(r\) Indefiniteness}
  Formally, a quadratic inequality induced by a symmetric matrix \(A\) can be expressed as the following,

  \begin{equation}
    x^T \left(\sum_{j\in J_+} \lambda_j v_jv_j^T\right)x +a^Tx \le b + \left(\sum_{j\in J_-} \lambda_j v_jv_j^T\right)
  \end{equation}

  \begin{itemize}
    \item For clarity, we say a quadratic inequality \(x^TAx + a^Tx \le b\) is \emph{rank-\(r\) indefinite} if first \(r\) eigenvalues are negative.
    \item In comparison, a maximization problem with matrix \(Q\) is rank-\(r\) indefinite if last \(r\) eigenvalues are nonnegative
  \end{itemize}

  Consider quadratic maximization, allow spectral decomposition,
  \[Q = \sum_{j \in J_{+}} \lambda_j v_jv_j^T - \sum_{j \in J_{-}} \lambda_j v_jv_j^T \]
  Then, we have the Many-small-cone \(\textsf{(MSC)} \) relaxation
  \begin{equation}\label{eq:qp_unc_rr_conic}
    \begin{aligned}
      \textsf{(MSC)} \quad \mx \quad & \sum_j \lambda_j y_j                                                               \\
      \st \quad                      & \sum_{j \in J_{-}} \lambda_{j} y_j - q^T x+z \le  \sum_{j \in J_{+}} \lambda_j y_j \\
                                     & y_j \ge (x_j^T v_j)^2, j= 1, ..., n
    \end{aligned}
  \end{equation}

  MSC is a relaxation of QCQP with \(n\) (many) \(2\)-d (small) SOCs
  \framebreak

  MSC should be implemented with a box or ball constraint as regularity (else \eqref{eq:qp_unc_rr_conic} will be unbounded.)
  \begin{itemize}
    \item ball: \(x\in B(0, \delta)\)
    \item box: \(x\in [0, 1]^n\)
    \item ellipsoid: \(x \in \{x: x^TAx + a^Tx \le \delta^2\}\)
    \item regularity implies,
          \begin{equation}
            y^Te = \|x\|^2
          \end{equation}
  \end{itemize}

  We implement a Branch-and-Bound algorithm to use MSC as node relaxations.
  \begin{itemize}
    \item We branch on \(j\) if \(y_j \ge (x_j^T v_j)^2\) is not \emph{tight}
    \item We test on rank-\(r\) indefinite problems. (where \(r\) is small)
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Preliminary Results}


  For box constrained nonconvex QP,
  \begin{itemize}
    \item \red{grb} is the Gurobi nonconvex QP.
    \item \red{bb\_msc}, \red{bb\_sdp}, \red{bb\_nsocp} is the branch and bound method using MSC, SDP, and SOCP as the node relaxation, respectively
  \end{itemize}

  \begin{table}[h!]
    \begin{tabular}{llrrrrrl}
      \toprule
      {} & prob\_num & solve\_time & best\_bound & best\_obj & node\_time & nodes    & method        \\
      \midrule
      0  & 12:0:0    & 0.134       & 258.6487    & 258.6487  & 0.000      & 726.0    & grb           \\
      1  & 12:0:0    & 0.040       & 258.6487    & 258.6487  & 0.025      & 1.0      & bb\_sdp       \\
      2  & 12:0:0    & 0.174       & 258.6488    & 258.6487  & 0.001      & 15.0     & \red{bb\_msc} \\
      3  & 12:0:0    & 15.395      & 258.6497    & 258.6485  & 0.003      & 1623.0   & bb\_nsocp     \\
      \midrule
      0  & 20:0:0    & 100.025     & 47.1953     & 47.1886   & 0.000      & 166519.0 & grb           \\
      1  & 20:0:0    & \red{0.427} & 47.1894     & 47.1886   & 0.002      & 21.0     & \red{bb\_msc} \\
      2  & 20:0:0    & 100.061     & 47.2924     & 46.9227   & 0.011      & 3001     & bb\_sdp       \\
      \midrule
      0  & 100:0:0   & 100.024     & 4966.1144   & 0.1682    & 0.000      & 7.0      & grb           \\
      1  & 100:0:0   & 100.043     & 109.0224    & -84.1555  & 0.073      & 1429.0   & bb\_sdp       \\
      2  & 100:0:0   & 1.609       & 0.1705      & 0.1682    & 0.026      & 17.0     & \red{bb\_msc} \\
      \midrule
      0  & 200:0:0   & 100.166     & 71975.3347  & 0.0743    & 0.000      & 1.0      & grb           \\
      1  & 200:0:0   & 4.228       & 0.0776      & 0.0743    & 0.118      & 15.0     & \red{bb\_msc} \\
      \bottomrule
    \end{tabular}
    \caption{\(r=1\)}

  \end{table}
  \begin{table}[h!]
    \begin{tabular}{llrrrrrl}
      \toprule
      {} & prob\_num & solve\_time & best\_bound & best\_obj & node\_time & nodes & method        \\
      \midrule
      0  & 100:0:0   & 100.019     & 5013.7126   & 0.2170    & 0.000      & 7.0   & grb           \\
      1  & 100:0:0   & 7.859       & 0.2195      & 0.2166    & 0.027      & 87.0  & \red{bb\_msc} \\
      \bottomrule
    \end{tabular}
    \caption{\(r=2, n=100\)}
  \end{table}
  \begin{table}[h!]
    \begin{tabular}{llrrrrrl}
      \toprule
      {} & prob\_num & solve\_time & best\_bound & best\_obj & node\_time & nodes  & method        \\
      \midrule
      0  & 100:0:0   & 100.015     & 11652.5910  & 526.5704  & 0.000      & 1.0    & grb           \\
      1  & 100:0:0   & 100.073     & 1540.5022   & 309.6513  & 0.019      & 1263.0 & \red{bb\_msc} \\
      \bottomrule
    \end{tabular}
    \caption{\(r=10, n=100\)}
  \end{table}
  \normalsize
  \framebreak
  For QP with a ball constrained, i.e., the Trust-region subproblem,
  \scriptsize
  \begin{table}[h!]
    \begin{tabular}{llrrrrrl}
      \toprule
      {} & prob\_num & solve\_time & best\_bound  & best\_obj    & node\_time & nodes   & method        \\
      \midrule
      0  & 12:0:0    & 100.052     & 2282.8435    & 2198.0355    & 0.000      & 62831.0 & grb           \\
      1  & 12:0:0    & 0.027       & 2198.0355    & 2198.0355    & 0.017      & 1.0     & \red{bb\_msc} \\
      2  & 12:0:0    & 0.013       & 2198.0355    & 2198.0354    & 0.002      & 2.0     & bb\_nsocp     \\
      \midrule
      0  & 120:0:0   & 0.134       & 1.852151e+06 & 1.852151e+06 & 0.024      & 1       & \red{bb\_msc} \\
      \midrule
      0  & 1200:0:0  & 7.472       & 1.874103e+09 & 1.874104e+09 & 2.994      & 1       & \red{bb\_msc} \\
      \bottomrule
    \end{tabular}
    \caption{QP with a ball constraint}
  \end{table}
  \normalsize

  \begin{itemize}
    \item MSC is very effective in the test problems. as \(r \nearrow \), the problem becomes hard.
    \item MSC is tight a single ball constraint (TRS)
    \item If there is no other Q constraints, we actually do not need full eigenvalue decomposition (only the nonconvex part is enough)
  \end{itemize}
\end{frame}



\begin{frame}[allowframebreaks]{Future Work}
  \begin{itemize}
    \item Extension to indefinite quadratic constraints
    \item Plug in our ADMM as a primal procedure.
  \end{itemize}
\end{frame}

\begin{frame}[allowframebreaks]{Future Work: Multiple Quadratic Constraints}
  We apply similar decomposition for every \(A_i, i=1,...,m\) in the constraints, let, \[Q = V_0 \diag(\lambda_0) V_0^T, A_i = V_i \diag(\lambda_i) V_i^T\]
  The MSC becomes
  \begin{align}
    \nonumber \mathrm{Maximize}\quad & y_0 ^T\lambda_0 + q^Tx                         \\
    \mathrm{s.t.} \quad              & V_i z_i = x                        & i=0,...,m \\
                                     & y_i ^T\lambda_i  + a_i^Tx  \le b_i & i=1,...,m \\
    \label{quad}                     & y_i = z_i \circ z_i                & i=0,...,m
  \end{align}
  \begin{itemize}
    \item In this formulation, we need \(m \times n\) auxillary pairs \((z, y)\) by including different bases \(V_i\)
    \item Actually this may not be necessary...
  \end{itemize}

  \framebreak
  Consider one indefinite \(A\) with a rank-\(r\) indefinite \(Q\), where,
  \begin{align*} \\
    A & = A_+ - A_-, A_+ \succeq 0, A_- \succeq 0                       \\
    Q & = \sum_{J_+} \lambda_j v_jv_j^T - \sum_{J_-} \lambda_j v_jv_j^T
  \end{align*}

  we can convexify \(A\) using the following procedure

  \begin{eqnarray}
    & x^TA_+ x - x^TA_-x + a^Tx \le b \\
    \Rightarrow \quad & x^T\left(A + V_-\red{\Gamma}V^T_-\right )x +a^Tx \le b + \underbrace{x^T(V_-\red{\Gamma}V^T_-)x}_{\diag(\Gamma)^Ty}
  \end{eqnarray}

  \framebreak

  \begin{itemize}
    \item We do not need extra sets of \(\{y\}\) for every Q constraint.
    \item The only question left is whether we can find \(\Gamma\) such that,
          \begin{equation}
            V_-\red{\Gamma}V^T_- - A_- \succeq 0
          \end{equation}
          This is related to the results on hidden convexity, \cite{burer_how_2017}, \cite{modaresi_convex_2017}
    \item This is a weaker construction than simultaneous diagonalization via congruence. \cite{wang_new_2021}
  \end{itemize}
\end{frame}
\begin{frame}[allowframebreaks]{Future Work: ADMM as a primal (local) solution}

  Notice,
  \begin{equation}
    \|x\|^2 = \max_{\|\xi\| \le \sqrt s} \xi^T x
  \end{equation}
  So we add slack variable \(s, t, \xi\) and bilinear constraint.
  \begin{align}
    \model{MSC} \quad \mathrm{Maximize: }\quad & y_0 ^T\lambda_0                     \\
    \mathrm{s.t.} \quad                        & (y,z,x) \in \Omega                  \\
                                               & y_i^Te \le t       & i=0, \cdots, m \\
    (\kappa) \quad                             & t= s               & i=0, \cdots, m \\
    (\mu)    \quad                             & \xi^Tx = t                          \\
                                               & \xi^T\xi \le s
  \end{align}
  If \(s, t, \xi, y, z, x\) is the solution, then \( y, z, x\) is the solution for MSC.

  This allows the augmented Lagrangian function,

  \begin{align*}
    \mathscr L\left(x,y,z,\xi,s,\kappa,\mu\right) & = - y_0 ^T\lambda_0 + \kappa(t-s) + \mu(\xi^Tx - t) + \frac{\rho}{2}(t-s)^2 + \frac{\rho}{2}(\xi^Tx - s)^2
  \end{align*}

  The ADMM iteration,

  \begin{align*}
    (x,y,z,t)^{k+1} & = {\arg\min}_{(x,y,z)\in\Omega, t\ge 0} L\left(x,y,z,\xi^k,s^k,\kappa^k,\mu^k\right)       \\
    (s, \xi)^{k+1}  & = {\arg\min}_{(s, \xi)\in\mathscr{Q}} L\left((x,y,z,t)^{k+1},\xi,s, \kappa^k, \mu^k\right) \\
    \kappa^{k+1}    & = \kappa^k + \rho\left(t^{k+1}-s^{k+1}\right)                                              \\
    \mu^{k+1}       & = \mu^k + \rho\left( \langle\xi^{k+1}, x^{k+1}\rangle - s^{k+1}\right)
  \end{align*}
  where \(\mathscr{Q(\cdot)}\) forms a simple SOCP for \(s, \xi\),
  \begin{equation}
    \mathscr{Q}(x) =\left\{(s,\xi): \|\xi\|^2 \le s\right\}
  \end{equation}

  \framebreak

  The size of auxillary variable \(\xi\) equals to \(n\), if \(r\) is small,

  We can actually shrink the size of above problem.
  \begin{align}
    \model{MSC} \quad \mathrm{Maximize: }\quad & y_0 ^T\lambda_0                                       \\
    \mathrm{s.t.} \quad                        & (y,z,x) \in \Omega                                    \\
                                               & y_i^Te = s                           & i=0, \cdots, m \\
    ( \mu_i, i\in I_+ )    \quad               & \xi_i \cdot (v_i^Tx) = y_i           & \red{i\in I_+} \\
                                               & \xi_i^2 \le y_i,  (v_i^Tx)^2 \le y_i
  \end{align}
  The ADMM,

  \begin{equation}
    \mathcal L = y^T\lambda + \sum_{i \in I_+} \mu_i \left [\xi_i \cdot(v_i^Tx) - y_i\right] + \frac{\rho}{2}\sum_{i \in I_+} (\xi_i \cdot (v_i^Tx) - y_i)^2
  \end{equation}

\end{frame}

\begin{frame}{Simple test on ADMM}




  \begin{itemize}
    \item We test the ADMM as a standalone local method on a few instances including random cases and a few ones in QPLIB.
    \item The ADMM is very promising
  \end{itemize}
  \begin{tabular}{llrrrrrl}
    \toprule
    {} & $n$:$m$:id  & $t$     & best\_bound & best\_obj & relax\_obj & nodes/iters & method    \\
    \midrule
    0  & 50:20:0     & 200.00  & 189.34      & 87.69     & 189.34     & 839.0       & grb       \\
    1  & 50:20:0     & 200.04  & 123.06      & 122.99    & 123.00     & 248.0       & admm\_msc \\
    0  & 50:50:0     & 200.00  & 197.20      & 68.50     & 197.20     & 395.0       & grb       \\
    1  & 50:50:0     & 200.39  & 159.97      & 157.23    & 157.36     & 86.0        & admm\_msc \\
    0  & 100:20:0    & 400.00  & 777.92      & 90.51     & 777.92     & 65.0        & grb       \\
    1  & 100:20:0    & 402.83  & 385.68      & 383.19    & 383.28     & 130.0       & admm\_msc \\
    0  & 100:50:0    & 400.01  & 817.60      & 115.00    & 817.60     & 12.0        & grb       \\
    1  & 100:50:0    & 406.29  & 367.47      & 358.75    & 359.59     & 61.0        & admm\_msc \\
    0  & 200:5:0     & 1000.00 & 3205.11     & 111.11    & 3205.11    & 2.0         & grb       \\
    1  & 200:5:0     & 1002.45 & 519.80      & 519.37    & 519.38     & 375.0       & admm\_msc \\
    0  & 200:20:0    & 1000.01 & 4050.97     & 135.87    & 4050.97    & 1.0         & grb       \\
    1  & 200:20:0    & 1006.92 & 528.21      & 519.58    & 519.88     & 74.0        & admm\_msc \\
    0  & QPLIB\_1055 & 200.00  & 33.28       & 33.03     & 33.28      & 911.0       & grb       \\
    1  & QPLIB\_1055 & 200.58  & 33.05       & 33.04     & 33.04      & 231.0       & admm\_msc \\
    \bottomrule
  \end{tabular}
\end{frame}



%%%%%%%%%%%%%%%
% appendix
%%%%%%%%%%%%%%%
% \begin{frame}[allowframebreaks]{Attempt for explicit disjunctions for inhomogeneous case}
%   \textbf{Alternatively}: branching on \(z - q^Tx\).

%   \textbf{Case I}: if \(z - q^Tx \le 0\), then,
%   \begin{align*}
%                                            & x^TRR^Tx - \underbrace{(q^Tx - z)}_{\Delta \ge 0} = (a^Tx)^2 \\
%     \text{Let: }\beta \ge 1 \Rightarrow \; & \red{\beta}\cdot \Delta\ge \|R^Tx\|^2                        \\
%     \Rightarrow \;                         & \red{(\beta - 1)}\cdot\Delta \ge (a^Tx)^2
%   \end{align*}

%   Can be rewritten as two rotated cones,
%   \begin{align*}
%     \beta + \Delta     & \ge \left\|\begin{array}{c} 2R^Tx \\ \beta - \Delta \end{array}\right\| \\
%     \beta - 1 + \Delta & \ge \left\|\begin{array}{c} 2a^Tx \\ \beta - 1 - \Delta \end{array}\right\| \\
%   \end{align*}
%   \framebreak

%   \textbf{Case II}: if \(z - q^Tx \ge 0\),

%   \begin{align*}
%     x^TRR^Tx +     & \underbrace{(z - q^Tx)}_{\Delta \ge 0} = (a^Tx)^2      \\
%                    & x^TRR^Tx + \red{\cancel{\Delta}} \le (a^Tx)^2          \\
%     \Rightarrow \; & \underbrace{a^Tx \ge \|R^Tx\|}_{\textsf{subcase II.1}}
%     \vee \underbrace{- a^Tx \ge \|R^Tx\|}_{\textsf{subcase II.2}}           \\
%   \end{align*}


%   This creates unbalanced subregions (same situation before.)

%   \framebreak

%   Try something similar to \textbf{Case I}

%   \begin{align*}
%     \beta \ge 1 \Rightarrow \; & \red{\beta}\cdot\Delta \ge (a^Tx)^2       \\
%                                & \red{(\beta - 1)}\cdot\Delta \ge (R^Tx)^2 \\
%                                & \red{\beta} \ge 1
%   \end{align*}

%   \(\Delta \doteq z - q^Tx\) is not bounded from above (we are maximizing \(z\))


%   \begin{align*}
%     \rho            & \ge (a^Tx)^2 \quad \dagger \\
%     \rho  -  \Delta & \ge \|R^Tx\|^2             \\
%   \end{align*}

%   \(\rho\) is not bounded from above \(\dagger\) will not be tight.
%   So the branch and bound is implemented on \(a^Tx \)
%   % Then we branch by last solution \(\rho^*\)
%   % \begin{equation*}
%   %   a^Tx \le \sqrt{\rho^*} \vee a^Tx \le \sqrt{\rho^*}
%   % \end{equation*}

% \end{frame}


\begin{frame}[allowframebreaks]{Bibliography}
  \bibliography{headers/qcqp}
  \bibliographystyle{apalike}
\end{frame}
\end{document}
