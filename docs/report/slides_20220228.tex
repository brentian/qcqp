\PassOptionsToClass{a4paper,10pt}{article} % for article mode
\PassOptionsToClass{utf8,aspectratio=1610,10pt}{beamer} % for beamer, handout, trans modes
\newcommand*{\BeamerswitchSpawn}[1]{
    \ShellEscape{... -jobname=\jobname#1 \jobname} %
}
\documentclass{beamerswitch}
\mode<article>{
  \usepackage[top=3cm, bottom=3cm, left=3cm, right=2cm]{geometry}
}
\mode<presentation>{

}
\usepackage{amsmath, amssymb, subfiles, bm, hyperref, graphicx}
\usepackage{mathrsfs}
\usepackage{caption, longtable, booktabs}
\usepackage{cancel}

% my cmd
%%%%%%%%%%%%%%%%
% start my commands
%%%%%%%%%%%%%%%%
\newcommand{\lm}{\lambda_\textbf{max}}
\newcommand{\trace}{\textbf{trace}}
\newcommand{\diag}{\textbf{diag}}
\newcommand{\rank}{\textbf{rank}}
\newcommand{\model}[1]{(\textbf{#1})}
\newcommand{\mx}{\mathbf{\max}\;}
\newcommand{\mn}{\mathbf{\min}\;}
\newcommand{\st}{\mathrm{s.t.\;}}
\newcommand{\ex}{\mathbf E}
\newcommand{\dx}{\;\bm dx}
\newcommand{\pr}{\mathbf P}
\newcommand{\id}{\mathbf I}
\newcommand{\bp}{\mathbb P}
\newcommand{\be}{\mathbb E}
\newcommand{\bi}{\mathbb I}
\newcommand{\bxi}{{\bm \xi}}
\newcommand{\va}{\mathbf{Var}}
\newcommand{\dif}{\mathbf{d}}
\newcommand{\minp}[2]{\min\{#1, #2\}}
\newcommand{\intp}{\mathbf{int}}
\newcommand{\apex}{\mathbf{apex}}
\newcommand{\conv}{\mathbf{conv}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\redsf}[1]{\textcolor{red}{\textsf{#1}}}
\newcommand{\real}{\mathbb{R}}

%%%%%%%%%%%%%%%%
% finish my commands
%%%%%%%%%%%%%%%%
\usefonttheme[onlymath]{serif}
\setbeamertemplate{theorems}[numbered]
\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{subsection in toc}[subsections numbered]
\setbeamertemplate{caption}[numbered]
% default navigation
\defbeamertemplate{navigation symbols}{mydefault}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}
% standout navigation
\defbeamertemplate{navigation symbols}{standout}{%
  \setbeamertemplate{navigation symbols}{}%
}

\BeforeBeginEnvironment{frame}{%
  \setbeamertemplate{navigation symbols}[mydefault]%
}

\makeatletter
\define@key{beamerframe}{standout}[true]{%
  \setbeamertemplate{navigation symbols}[standout]
}
\makeatother

\title{QCQP: Progress Report}
\begin{document}

\author{
  Chuwen Zhang
}

\frame{\titlepage
}
\frame{\tableofcontents}

% Diagonalization for QCQP
\section{Diagonalization for QCQP}



% Interior Point Trust Region Method for QCQP

\section{Interior Point Trust Region Method for QCQP}
\begin{frame}[allowframebreaks]{Interior Trust Region Method for Convex and nonconvex QP}
  Recall \cite{ye_extension_1989}, \cite{ye_affine_1992}
  \begin{align*}
    \min q(x)\doteq ~ & x^TQx + q^Tx    \\
    \st             ~ & Ax = b, x \ge 0
  \end{align*}
  We solve by successive trust region subproblems with affine scaling
  \begin{align*}
    \min q(x)\doteq ~ & x^TQx + q^Tx                               \\
    \st             ~ & Ax = b, x \ge 0                            \\
                      & \|(D^0)^{-1}(x - x^0)\|^2  \le \beta^2 < 1
  \end{align*}

  \begin{enumerate}
    \item  Affine scaling: \(D^0 = \diag(x^0)\)
    \item  Alternatively, one can add a barrier term: \(- \ln(x)^Te \approx - \left(\kappa^{k+1} \alpha / \sqrt{n}\right) e^{T} D^{-1}\left(x-x^{k}\right)\)
    \item  Solve TRS at iteration \(k\) by solving a linear system.
    \item  Even if the problem is nonconvex, the TRS produces a global solution at iteration \(k\).
  \end{enumerate}
\end{frame}
\begin{frame}[allowframebreaks]{Interior TRS for Diagonalized Box-QP}
  Consider box QP in (diagonalized) standard form, \(x \in [0, u]\), we have the the quadratic subproblem (QPS) using the interior trust region method,
  \begin{equation}\label{eq.interior.boxqp}
    \begin{aligned}
      \max ~ & x^T\Lambda x + q^Tx  + \mu \sum_j \ln x_j & \stackrel{\mu =\kappa}{\approx} x^T\Lambda x + q^Tx + \frac{\alpha \kappa}{\sqrt n} e^T(Dx-e) \\
      \st ~  & x_j \le u_j                               & (\theta)                                                                                      \\
             & \|Dx - e\| \le \beta^2                    & (\kappa)
    \end{aligned}
  \end{equation}
  where \(D = \diag(x^0)^{-1}\) is the affine scaling matrix.
  \framebreak

  Lagrangian function,
  \begin{align*}
    L ~ = & -x^T\Lambda x - q^Tx - \frac{\alpha \kappa}{\sqrt n} e^T(Dx-e) \\
          & + \theta^Tx - \theta^Tu                                        \\
          & + \kappa x^TD^2x - 2\kappa e^TDx + \kappa(e^Te - \beta^2)
  \end{align*}
  The first order condition for QPS,

  \begin{align*}
    2(\kappa \cdot D^2 - \Lambda)x + \theta         & = q + \kappa \cdot De \cdot\left (2 + \frac{\alpha}{\sqrt n} \right ) \\
    \theta \circ (x - u)                            & = 0                                                                   \\
    \kappa \left (\|Dx - e\|^2 - \beta^2   \right ) & = 0
  \end{align*}
  Similar to \cite{ye_extension_1989}, it is possible to drop complementary for ellipsoid condition and \(\kappa\)

  \framebreak
  Add second order condition,
  \begin{align*}
    S(\kappa)                             & = \kappa \cdot D^2 - \red{\Lambda} \succeq 0                    & \dagger  \\
    2S (\kappa) \cdot \tilde \theta       & = \theta                                                        &          \\
    2S (\kappa) \cdot (x + \tilde \theta) & = q + \kappa De\cdot \left (2 + \frac{\alpha}{\sqrt n} \right ) & \ddagger \\
  \end{align*}

  \begin{enumerate}
    \item We can clearly construct a lower bound for \(\kappa\), by making \(\dagger\) psd and RHS of \(\ddagger\) nonnegative.
    \item We know \(x + \tilde \theta \ge 0, x\le u \), by suitably choose \(\kappa > 0\), we can always find \(x + \tilde \theta \ge 0\)
    \item Next we find \(\tilde \theta \) to make \(x \le u, \theta \circ (x - u) = 0\)
  \end{enumerate}
\end{frame}

\begin{frame}[allowframebreaks]{Interior TRS for Diagonalized QCQP}

  With simultaneous convexification, consider the subproblem with affine scaling,

  \begin{equation}\label{eq.int.qcqp}
    \begin{aligned}
      \max ~ & x^TV\Gamma_0V^T x - x^T\tilde Q x + q^Tx                         \\
      \st  ~ & x^T\tilde A_j x + a_j ^Tx - b_j \le x^TV\Gamma_j V^Tx & (\tau)   \\
             & \left \|DV^Tx - e  \right \|  \le \beta               & (\kappa) \\
             & 0 \le V^Tx \le u                                      & (\theta)
    \end{aligned}
  \end{equation}

  Similarly,
  \begin{equation}\label{eq.int.qcqp.trs}
    \begin{aligned}
      S & = \red{\kappa D^2} - \Gamma_0 - \tau^T \bm  \Gamma                                          \\
      0 & = 2\left(\tilde Q + \tau^T \bm A + V^TSV\right) x + V\theta + \tau^T\bm a - q - 2\kappa VDe \\
      0 & \preceq  \tilde Q + \tau^T \bm A + V^TSV                                                    \\
      0 & = \theta \circ (V^Tx-u)                                                                     \\
      0 & = \tau_j \cdot (x^T\tilde A_j x + a_j ^Tx - b_j - x^TV\Gamma_j V^Tx)
    \end{aligned}
  \end{equation}
  However,

  \begin{enumerate}
    \item It is hard to find an interior (start) point
    \item There is no obvious solution for \eqref{eq.int.qcqp.trs}
    \item There is no guarantee for global minimum in the TRS
  \end{enumerate}
\end{frame}
\begin{frame}[allowframebreaks]{Interior TRS for MSC Relaxation}
  Instead, consider the MSC relaxation to QCQP.
  \begin{equation}\label{eq.int.msc}
    \begin{aligned}
      \max ~ & \gamma_0^T y + q^Tx                                           \\
      \st  ~ & x^T\tilde A_j x + a_j ^Tx - b_j \le \gamma_j^Ty & j=1, ..., m \\
             & (V^T x)^2 \le y
    \end{aligned}
  \end{equation}
  Let \((x^0, y^0)\) be the solution to the above relaxation, then we relates the primal feasibility to the residual of quadratic approximation. Let \(c(\Gamma)\) be the residual of quadratic approximation by positive diagonal matrix \(\Gamma\),
  \[c (\Gamma) \doteq x^TV\Gamma V^T x - \gamma^Ty \]
  Then an oracle to check the primal feasibility can be represented by the following system,
  \begin{align*}
    \tilde p_j           & = x^T\tilde A_j x + a_j ^Tx - b_j - \gamma_j^Ty \\
    c_j = c_j (\Gamma_j) & = x^TV\Gamma_jV^T x - \gamma_j^Ty               \\
    p_j                  & \doteq x^TA_jx + a_j^Tx - b_j                   \\
                         & = \tilde p_j - c_j
  \end{align*}

  Given \(\tilde p_j \le 0\) at hand, a sufficient condition to \(p_j \le 0\) can be given as \(c_j = 0\). Since \(c_j \le 0\) is ensured by the cones, it motivates a penalty method to deal with the counterpart.

  \framebreak

  We already have \(x^TV\Gamma V^Tx \le \gamma^T y\). If the reverse is also true, then it implies \(p_j \le 0\) holds for all \(j = 1, ..., m\).

  We now able to construct a trust region subproblem with \((d, v, r)\) being the trial step such that,

  \[x_+ = x^0 + v, d = V^Tv, ~y_+ = y^0 + r\]


  Let a penalty term,
  \[P(d, r) = \red{d^T\Gamma d + 2 d^T \Gamma V^T x^0 - \gamma^T r}\]

  such that,
  \[P(d, r) + c(\Gamma) = x_+ V\Gamma V^Tx_+ - \gamma^T y_+\]

  Notice if we place second-order cone for \((x_+, y_+)\) by letting \(P(d, r) + c(\Gamma) \le 0\), we have \( P(d, r) + c(\Gamma) = - |\cdot |\) that allows \(\mathcal L_1\) penalty function.
  \framebreak

  Altogether, we arrive at a trust region subproblem with \(\mathcal L_1\) penalty, say \(\mathcal L_1\)-TRS
  \begin{equation}\label{eq.msc.trs}
    \begin{aligned}
      \max ~        & \gamma_0^T r + q^Tv  + \sigma \red{P(d, r)}                                       \\
      \st  ~        & v^T\tilde A_j v + v^T (a_j + 2 \tilde A_jx^0) - \gamma_j^Tr \le 0 & j = 1, ..., m \\
                    & \left(V^Tx^0 + d\right)^2 \le y^0 + r                                             \\
                    & V^Tv = d                                                                          \\
      \red {(\mu)}~ & d^TDd + r^TDr \le \epsilon                                        &
    \end{aligned}
  \end{equation}

  The problem itself is nonconvex. Similar to affine scaling algorithms, this problem can be solved by trying different \(\mu\).

  \framebreak

  Consider problem \(F(\sigma, \mu)\)
  \begin{equation}\label{eq.msc.trs}
    \begin{aligned}
      F(\sigma, \mu)\doteq  \max ~ & \gamma_0^T r + q^Tv  + \red{\sigma \cdot P(d, r)}  -  \red{\mu \cdot( d^TDd + r^TDr )}               \\
      \st  ~                       & v^T\tilde A_j v + v^T (a_j + 2 \tilde A_jx^0) - \gamma_j^Tr \le 0                      & j=1, ..., m \\
                                   & \left(V^Tx^0 + d\right)^2 \le y^0 + r                                                                \\
                                   & V^Tv = d
    \end{aligned}
  \end{equation}

  Rearange the objective,

  \begin{align*}
      & \gamma_0^T r + q^Tv + \red{\sigma \cdot P(d, r)}  -  \red {\mu \cdot( d^TDd + r^TDr )}                                                  \\
    = & d^T (\sigma \Gamma - \mu D) d - r^T\left(\mu D\right)r +  d^T\left(2\sigma\Gamma V^T x^0 \right) + (\gamma_0 - \sigma\gamma^T )r + q^Tv
  \end{align*}

  \begin{enumerate}
    \item if \(\sigma \Gamma - \mu D \preceq 0\), the problem is convex that can be solved in polynomial time.
    \item the preliminary results indicate the effectiveness of \(\mathcal L_1\)-TRS.
    \item however, we should carefully choose \(\Gamma, D, \sigma, \mu\).
  \end{enumerate}
\end{frame}

\begin{frame}[allowframebreaks]{To-tos for L1 TRS}
  Here are the bottom lines,

  \begin{enumerate}
    \item \(\sigma \Gamma - \mu D \preceq 0\), which guarantees the convexity (and global minimum?)
    \item by exact penalty, the original TRS produces \(P(d, r) + c(\Gamma) = 0\) with finite \(\sigma\), also holds if relax the ellipsoid (convexify) ?
    \item solve by varying \(\sigma\) or instead changing \(x\) ?
    \item can we find branching strategy based on this method ? see (Tseng and Ye 2002)
  \end{enumerate}
\end{frame}
\begin{frame}[allowframebreaks]{  Implementation of MSC based Interior Point Trust Region Method  }
  We add some new terms to introduce a slightly different formulation for MSC,

  \begin{align*}
    \max ~ & f                                                                                                           \\
    \st ~  & f ~ + x^T\tilde A_0x + x^Ta_0                                                \le \gamma_0^T y               \\
           & x^T\tilde A_j x + x^T a_j - b_j \le \gamma_j^Ty                                               & j=1, ..., m \\
           & \left (V^Tx \right )^2 \le y
  \end{align*}
  where,
  \begin{align*}
    \tilde A_0 & = V\Gamma_0 V^T - A_0                \\
    \tilde A_j & = V\Gamma_j V^T + A_j, ~ j=1, ..., m \\
  \end{align*}

  \framebreak
  TRS: \(x_+ = x^0 + v, d = V^Tv, ~y_+ = y^0 + r\)
  \begin{equation}
    \begin{aligned}
      F(\sigma, \mu)\doteq  \max ~ & \delta  + \red{\sigma \cdot P(d, r)}  -  \red{\mu \cdot( d^TDd + r^TDr )}                                                         \\
      = ~                          & \delta  -  d^T (\mu D - \sigma \Gamma) d - r^T\left(\mu D\right)r  + 2 \sigma d^T \Gamma x^0 - \sigma \gamma^T r                  \\
      \st  ~                       & \delta + v^T\tilde A_0 v + v^T ( - a_0 + 2 \tilde A_0 x^0) \le \gamma_0^Tr                                                        \\
                                   & v^T\tilde A_j v + v^T (a_j + 2 \tilde A_jx^0)   \le  \gamma_j^Tr                                                 & j = 1 , ..., m \\
                                   & \left(V^Tx^0 + d\right)^2 \le y^0 + r                                                                                             \\
                                   & V^Tv = d                                                                                                                          \\
    \end{aligned}
  \end{equation}

\end{frame}
\begin{frame}[allowframebreaks]{Appendix}
  First and second-order condition for general QCQP,
  We have \(Q = \tilde{Q} - V\Gamma_0V^T, A_j = \tilde{A_j} - V\Gamma_j V^T\) such that \(\tilde{Q} \succeq 0, \tilde A_j \succeq 0, \forall j\). Let \(\bm A = \begin{bmatrix}    A_1 \\ ... \\ A_m  \end{bmatrix}, \bm a = \begin{bmatrix}
    a_1^T \\...\\a_m^T  \end{bmatrix}\). \(D\) is a diagonal matrix, \(D = \diag(V^Tx^0)^{-1} \)
  \begin{align*}
    L = & ~ x^T\left[\tilde Q + \tau^T \bm A + V\left (\red{\kappa D^2} - \Gamma_0 - \tau^T \bm \Gamma \right )V^T\right ]x \\
        & + (\tau^T\bm a)^T x- \tau^T \bm b + \theta^TV^Tx - \theta^Tu                                                      \\
        & - 2 \kappa x^T VDe - x^Tq + \kappa e^Te - \kappa \beta^2
  \end{align*}
  \framebreak

  First and second order condition for a local minimum
  \begin{align*}
    S & = \red{\kappa D^2} - \Gamma_0 - \tau^T \bm  \Gamma                                          \\
    0 & = 2\left(\tilde Q + \tau^T \bm A + V^TSV\right) x + V\theta + \tau^T\bm a - q - 2\kappa VDe \\
    0 & \preceq  \tilde Q + \tau^T \bm A + V^TSV                                                    \\
    0 & = \theta \circ (V^Tx-u)                                                                     \\
    0 & = \tau_j \cdot (x^T\tilde A_j x + a_j ^Tx - b_j - x^TV\Gamma_j V^Tx)
  \end{align*}
\end{frame}
\begin{frame}[allowframebreaks]{Bibliography}
  \bibliography{headers/qcqp}
  \bibliographystyle{apalike}
\end{frame}
\end{document}