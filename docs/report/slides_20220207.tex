\documentclass[aspectratio=1610, 9pt]{beamer}
\usepackage[english]{babel}
\usepackage{amsmath, amsthm, subfiles, bm, hyperref, graphicx}
\usepackage{mathrsfs}
\usepackage{caption, longtable, booktabs}
\usepackage{cancel}

% my cmd
%%%%%%%%%%%%%%%%
% start my commands
%%%%%%%%%%%%%%%%
\newcommand{\lm}{\lambda_\textrm{max}}
\newcommand{\trace}{\mathbf{trace}}
\newcommand{\diag}{\mathbf{diag}}
\newcommand{\model}[1]{(\textbf{#1})}
\newcommand{\mx}{\mathbf{\max}\;}
\newcommand{\mn}{\mathbf{\min}\;}
\newcommand{\st}{\mathrm{s.t.\;}}
\newcommand{\ex}{\mathbf E}
\newcommand{\dx}{\;\bm dx}
\newcommand{\pr}{\mathbf P}
\newcommand{\id}{\mathbf I}
\newcommand{\bp}{\mathbb P}
\newcommand{\be}{\mathbb E}
\newcommand{\bi}{\mathbb I}
\newcommand{\bxi}{{\bm \xi}}
\newcommand{\va}{\mathbf{Var}}
\newcommand{\dif}{\mathbf{d}}
\newcommand{\minp}[2]{\min\{#1, #2\}}
\newcommand{\intp}{\mathbf{int}}
\newcommand{\apex}{\mathbf{apex}}
\newcommand{\conv}{\mathbf{conv}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\usefonttheme[onlymath]{serif}

%%%%%%%%%%%%%%%%
% finish my commands
%%%%%%%%%%%%%%%%

% theorem environments
\setbeamertemplate{footline}[frame number]


\makeatletter
\patchcmd{\beamer@sectionintoc}
{\ifnum\beamer@tempcount>0}
{\ifnum\beamer@tempcount>-1}
{}
{}
\beamer@tocsectionnumber=0
\makeatother

% set the toc to be using the number
\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{subsection in toc}[subsections numbered]

\hypersetup{pdfstartview={Fit}}

\AtBeginSection[]
{
    \begin{frame}
        \frametitle{Table of Contents}
        \tableofcontents[        currentsection,         currentsubsection,         subsectionstyle=show/shaded/hide,]
    \end{frame}
}


\defbeamertemplate{section page}{mine}[1][]{%
    \begin{centering}
        \vskip1em\par
        \begin{beamercolorbox}[sep=12pt, center]{part title}
            \usebeamerfont{section title}\insertsection\par
        \end{beamercolorbox}
    \end{centering}
}

\defbeamertemplate{subsection page}{mine}[1][]
{
    \begingroup
    \begin{beamercolorbox}[sep=8pt, center]{subsection title}
        \usebeamerfont{subsection title}\insertsubsection\par
    \end{beamercolorbox}
    \endgroup
}


\setbeamertemplate{section page}[mine]
\setbeamertemplate{subsection page}[mine]

\begin{document}


\title{QCQP: Progress Report}

\author{
  Chuwen Zhang
}
\maketitle

\begin{frame}{The QCQP}
  We consider the QCQP,
  \begin{equation}
    \label{eq:inhoqcqp}
    \begin{aligned}
      \model{QCQP} \quad \mx \quad & x^T Qx + q^T x                                        \\
      \textrm{s.t.} \quad          & x^T A_i x + a_i^T x \hspace{0.27em} (\le, =, \ge) b_i \\
    \end{aligned}
  \end{equation}
\end{frame}
\begin{frame}[allowframebreaks]{Rank-\(r\) Indefiniteness}

  Formally, a quadratic inequality induced by a symmetric matrix \(A\) can be expressed as the following,

  \begin{equation}
    x^T \left(\sum_{j\in J_+} \lambda_j v_jv_j^T\right)x +a^Tx \le b + x^T\left(\sum_{j\in J_-} \lambda_j v_jv_j^T\right)x
  \end{equation}

  \begin{itemize}
    \item For clarity, we say a quadratic inequality \(x^TAx + a^Tx \le b\) is \emph{rank-\(r\) indefinite} if first \(r\) eigenvalues are negative.
    \item In comparison, a maximization problem with matrix \(Q\) is rank-\(r\) indefinite if last \(r\) eigenvalues are nonnegative.
  \end{itemize}

  \framebreak

  Consider quadratic maximization with no other constraint,
  \begin{equation}
    \begin{aligned}
      \mx \quad & x^TQx + q^Tx \\
    \end{aligned}
  \end{equation}

  except for a regularity on \(x\) to avoid unboundedness.
  \begin{itemize}
    \item ball: \(x\in B(0, \delta)\),
    \item box: \(x\in [0, 1]^n\)
    \item ellipsoid: \(x \in \{x: x^TAx + a^Tx \le \delta^2\}\)
  \end{itemize}

  \begin{equation}\label{eq:qp_unc_rr_conic}
    \begin{aligned}
      \mx \quad & \sum_{j\in J_+} \lambda_j y_j - x^TQ_-x  + q^Tx \\
      \st \quad & y_j \ge (x_j^T v_j)^2, j= 1, ..., n
    \end{aligned}
  \end{equation}

  In the ball-constrained case, one can bound \(y\) by,
  \begin{equation}
    y^Te = \|x\|^2 \le \delta^2
  \end{equation}
\end{frame}

\begin{frame}[allowframebreaks]{Improve Old MSC Relaxation}
  Suppose now we have QCQP with \(m\) constraints, where
  \begin{align*}
    Q = V_0\Lambda_0V_0^T, A_i = V_i\Lambda_iV_i^T
  \end{align*}
  The MSC formulation is the following,
  \begin{align}
    \nonumber \mathrm{Maximize}\quad & y_0 ^T\diag(\Lambda_0) + q^Tx                         \\
    \mathrm{s.t.} \quad              & V_i^T x = z_i                             & i=0,...,m \\
                                     & y_i ^T\diag(\Lambda_i)  + a_i^Tx  \le b_i & i=1,...,m \\
    \label{quad}                     & y_i = z_i \circ z_i                       & i=0,...,m
  \end{align}
  \begin{itemize}
    \item In this formulation, we need \((m + 1) \times n\) auxillary pairs \(\{(z_i, y_i)\}_{i=0}^{m+1}\) by allowing different bases \(V_i\)
    \item Actually this may not be necessary...
  \end{itemize}

  \framebreak
  Consider one indefinite \(A\) with a rank-\(r\) indefinite \(Q\), we can convexify \(A\) by\dots
  \begin{align*}
    Q = V_0\Lambda_0V_0^T
  \end{align*}
  \begin{eqnarray}
    & x^TA x + a^Tx \le b \\
    \Rightarrow \quad & x^T\left(A + V_0\red{\Gamma}V^T_0\right )x +a^Tx \le b + \underbrace{x^T(V_0\red{\Gamma}V^T_0)x}_{\diag(\Gamma)^Ty}
  \end{eqnarray}
  In this case, we have \(n\) \((z, y)\) pairs.
\end{frame}
\begin{frame}[allowframebreaks]{Conditions to Convexify \(x^TAx + a^Tx \le b\)}
  Consider
  \begin{eqnarray}
    \mathcal A = &  \{x \mid x^T\left(A + V_0\red{\Gamma}V^T_0\right )x +a^Tx \le b + x^T(V_0\red{\Gamma}V^T_0)x\}\\
    \mathcal A \text{ is convex }\Rightarrow  &A + V_0\red{\Gamma}V^T_0 \succeq 0
  \end{eqnarray}
  Let \(v_1, ..., v_r, r \le n\) be columns of \(V_0\),

  \begin{itemize}
    \item if \(V_0\) is nonsingular (\(r = n\)), we use \(n\) basic vectors, it is always possible to find such \(\Gamma\). For example, let \(\sigma = - \lambda_{\min} (A)\), then
          \[A + \sigma \cdot V_0V_0^T = A + \sigma I \succeq 0\]
          This is a weaker construction than SD, \cite{jiang_simultaneous_2016}. For example,
          \begin{align*}
            Q = \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix}, A = \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}
          \end{align*}
          \{Q, A\} are not SD but yet \(A + I \succeq 0\)
          This means we need \red{at most} \(n\) \((z, y)\) pairs.
          \framebreak
    \item if \(V_0\) is singular (\(r < n\)), \(\Gamma\) may not exist. For example, if \(V_0 = v_1v_1^T\). We know that the smallest eigenvalue of \(A + \alpha v_1v_1^T\) is bounded by the second smallest eigenvalue of \(A\)


    \item if \(V_0\) is singular (\(r < n\)), and \(A\) is negative definite of rank \(m\), i.e.,
          \[A = - \sum_{j=1}^m \mu_j u_ju_j^T\]

          Can we find \(\Gamma\), such that

          \[V_0 \Gamma V_0^T + A = \sum_{j=1}^r \gamma_j v_jv_j^T - \sum_{j=1}^m \mu_j u_ju_j^T\]
          is psd?
  \end{itemize}

\end{frame}

\begin{frame}{ADMM using improved MSC}
  \begin{align}
    \model{MSC} \quad \mx \quad & y ^T\lambda_0                                       \\
    \mathrm{s.t.} \quad         & (y,z,x) \in \Omega                                  \\
    ( \mu_i)    \quad           & \xi_i \cdot (v_i^Tx) = y_i           & \red{i\in I} \\
                                & \xi_i^2 \le y_i,  (v_i^Tx)^2 \le y_i
  \end{align}
  The ADMM,

  \begin{equation}
    \mathcal L = y^T\lambda + \sum_{i \in I} \mu_i \left [\xi_i \cdot(v_i^Tx) - y_i\right] + \frac{\rho}{2}\sum_{i \in I} (\xi_i \cdot (v_i^Tx) - y_i)^2
  \end{equation}

  At iteration \(k\),

  \begin{align*}
    (x,y,z,t)^{k+1} & = {\arg\min}_{(x,y,z)\in\Omega, t\ge 0} L\left(x,y,z,\xi^k,s^k,\kappa^k,\mu^k\right)    \\
    (\xi)^{k+1}     & = {\arg\min}_{(\xi)\in\mathscr{Q}} L\left((x,y,z,t)^{k+1},\xi,s, \kappa^k, \mu^k\right) \\
    \kappa^{k+1}    & = \kappa^k + \rho\left(t^{k+1}-s^{k+1}\right)                                           \\
    \mu^{k+1}       & = \mu^k + \rho\left( \langle\xi^{k+1}, x^{k+1}\rangle - s^{k+1}\right)
  \end{align*}

  As a comparison, see the full-dimensional \hyperlink{oldad}{ADMM}.
\end{frame}

\begin{frame}[allowframebreaks]{Box QP}
  Recently, \cite{luo_new_2019} considers rank-\(r\) indefinite QP under linear and convex quadratic constraints. We mark \textsf{Luo, ADMBB} as the method of using ADMM + BB.  Their method is basically the following:
  \begin{itemize}
    \item The ADMM penalizes \(V^Tx = Z\).
    \item The BB procedure is the same, except for the branching rules. In \textsf{Luo, ADMBB}, the pivot is calculated by \(z := \frac{1}{2}(l_z + u_z)\) instead of \(z^*\)
    \item In the case of Box QP, the convex relaxation is the same. They use CPLEX to solve QCP directly.
    \item The instances are generated following the tradition in \cite{le_an_solving_1997}.
  \end{itemize}

  \framebreak

  \begin{table}[h!]
    \centering
    \begin{tabular}{llllll}
      \toprule
      \(n\) & \(r\) & solve\_time & nodes & \#ADMM & method              \\
      \midrule
      50    & 5     & 29.089      & 1122  & -      & grb                 \\
      50    & 5     & 11.059      & 529   & 2      & bb\_msc             \\
      50    & 5     & 8.114       & 245   & 3      & \textsf{Luo, ADMBB} \\
      100   & 5     & 90.549      & 439   & -      & grb                 \\
      100   & 5     & 9.683       & 529   & 4      & bb\_msc             \\
      100   & 5     & 8.776       & 305   & 5      & \textsf{Luo, ADMBB} \\
      150   & 5     & 241.730     & 439   & -      & grb                 \\
      150   & 5     & 31.602      & 537   & 4      & bb\_msc             \\
      150   & 5     & 12.56       & 305   & 8      & \textsf{Luo, ADMBB} \\
      200   & 5     & 0.082       & 3     & -      & grb                 \\
      200   & 5     & 34.344      & 315   & 7      & bb\_msc             \\
      200   & 5     & 58.51       & 187   & 4      & \textsf{Luo, ADMBB} \\
      \bottomrule
    \end{tabular}
    \caption{The box QP instances generated using the method in \cite{luo_new_2019}.
      We terminate Gurobi very early here (gap \(\le e^{-3}\))}

    \framebreak

    \begin{itemize}
      \item In Box-QP, our relaxation will produce the feasible solutions, and thus the ADMM or any other primal method is not critical
      \item In \textsf{Luo, ADMBB}, we can also see the number of required or invoked ADMM iterations are limited.
    \end{itemize}
  \end{table}


\end{frame}

\begin{frame}[allowframebreaks]{QCQP}
  \begin{table}[h!]
    \centering
    \begin{tabular}{llrrrrrl}
      \toprule
      {} & prob\_num & solve\_time & best\_bound & best\_obj & node\_time & nodes  & method  \\
      \midrule
      0  & 100:10:0  & 500.008     & 4034.5945   & 0.1978    & 0.00       & 60.0   & grb     \\
      1  & 100:10:0  & 500.710     & 0.2625      & 0.1946    & 0.13       & 1643.0 & bb\_msc \\
      \bottomrule
    \end{tabular}
  \end{table}
\end{frame}

\begin{frame}[allowframebreaks]{Future Work}
  \begin{itemize}
    \item Extension to an indefinite quadratic inequalities
    \item Plug in ADMM as primal feasible solution.
  \end{itemize}
\end{frame}


\begin{frame}[allowframebreaks]{\hypertarget{oldad}{Appendix: ADMM in the original \(x\)}}

  Notice,
  \begin{equation}
    \|x\|^2 = \max_{\|\xi\| \le \sqrt s} \xi^T x
  \end{equation}
  So we add slack variable \(s, t, \xi\) and bilinear constraint.
  \begin{align}
    \model{MSC} \quad \mathrm{Maximize: }\quad & y_0 ^T\lambda_0                     \\
    \mathrm{s.t.} \quad                        & (y,z,x) \in \Omega                  \\
                                               & y_i^Te \le t       & i=0, \cdots, m \\
    (\kappa) \quad                             & t= s               & i=0, \cdots, m \\
    (\mu)    \quad                             & \xi^Tx = t                          \\
                                               & \xi^T\xi \le s
  \end{align}
  If \(s, t, \xi, y, z, x\) is the solution, then \( y, z, x\) is the optimal solution for MSC.

  This allows the augmented Lagrangian function,

  \begin{align*}
    \mathscr L\left(x,y,z,\xi,s,\kappa,\mu\right) & = - y_0 ^T\lambda_0 + \kappa(t-s) + \mu(\xi^Tx - t) + \frac{\rho}{2}(t-s)^2 + \frac{\rho}{2}(\xi^Tx - s)^2
  \end{align*}

  The ADMM iteration,

  \begin{align*}
    (x,y,z,t)^{k+1} & = {\arg\min}_{(x,y,z)\in\Omega, t\ge 0} L\left(x,y,z,\xi^k,s^k,\kappa^k,\mu^k\right)       \\
    (s, \xi)^{k+1}  & = {\arg\min}_{(s, \xi)\in\mathscr{Q}} L\left((x,y,z,t)^{k+1},\xi,s, \kappa^k, \mu^k\right) \\
    \kappa^{k+1}    & = \kappa^k + \rho\left(t^{k+1}-s^{k+1}\right)                                              \\
    \mu^{k+1}       & = \mu^k + \rho\left( \langle\xi^{k+1}, x^{k+1}\rangle - s^{k+1}\right)
  \end{align*}
  where \(\mathscr{Q(\cdot)}\) forms a simple SOCP for \(s, \xi\),
  \begin{equation}
    \mathscr{Q}(x) =\left\{(s,\xi): \|\xi\|^2 \le s\right\}
  \end{equation}

\end{frame}



%%%%%%%%%%%%%%%
% appendix
%%%%%%%%%%%%%%%
% \begin{frame}[allowframebreaks]{Attempt for explicit disjunctions for inhomogeneous case}
%   \textbf{Alternatively}: branching on \(z - q^Tx\).

%   \textbf{Case I}: if \(z - q^Tx \le 0\), then,
%   \begin{align*}
%                                            & x^TRR^Tx - \underbrace{(q^Tx - z)}_{\Delta \ge 0} = (a^Tx)^2 \\
%     \text{Let: }\beta \ge 1 \Rightarrow \; & \red{\beta}\cdot \Delta\ge \|R^Tx\|^2                        \\
%     \Rightarrow \;                         & \red{(\beta - 1)}\cdot\Delta \ge (a^Tx)^2
%   \end{align*}

%   Can be rewritten as two rotated cones,
%   \begin{align*}
%     \beta + \Delta     & \ge \left\|\begin{array}{c} 2R^Tx \\ \beta - \Delta \end{array}\right\| \\
%     \beta - 1 + \Delta & \ge \left\|\begin{array}{c} 2a^Tx \\ \beta - 1 - \Delta \end{array}\right\| \\
%   \end{align*}
%   \framebreak

%   \textbf{Case II}: if \(z - q^Tx \ge 0\),

%   \begin{align*}
%     x^TRR^Tx +     & \underbrace{(z - q^Tx)}_{\Delta \ge 0} = (a^Tx)^2      \\
%                    & x^TRR^Tx + \red{\cancel{\Delta}} \le (a^Tx)^2          \\
%     \Rightarrow \; & \underbrace{a^Tx \ge \|R^Tx\|}_{\textsf{subcase II.1}}
%     \vee \underbrace{- a^Tx \ge \|R^Tx\|}_{\textsf{subcase II.2}}           \\
%   \end{align*}


%   This creates unbalanced subregions (same situation before.)

%   \framebreak

%   Try something similar to \textbf{Case I}

%   \begin{align*}
%     \beta \ge 1 \Rightarrow \; & \red{\beta}\cdot\Delta \ge (a^Tx)^2       \\
%                                & \red{(\beta - 1)}\cdot\Delta \ge (R^Tx)^2 \\
%                                & \red{\beta} \ge 1
%   \end{align*}

%   \(\Delta \doteq z - q^Tx\) is not bounded from above (we are maximizing \(z\))


%   \begin{align*}
%     \rho            & \ge (a^Tx)^2 \quad \dagger \\
%     \rho  -  \Delta & \ge \|R^Tx\|^2             \\
%   \end{align*}

%   \(\rho\) is not bounded from above \(\dagger\) will not be tight.
%   So the branch and bound is implemented on \(a^Tx \)
%   % Then we branch by last solution \(\rho^*\)
%   % \begin{equation*}
%   %   a^Tx \le \sqrt{\rho^*} \vee a^Tx \le \sqrt{\rho^*}
%   % \end{equation*}

% \end{frame}


\begin{frame}[allowframebreaks]{Bibliography}
  \bibliography{headers/qcqp}
  \bibliographystyle{apalike}
\end{frame}
\end{document}
